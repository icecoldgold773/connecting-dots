{
    "network": {
        "modelName": "model8",
        "activation": "relu",
        "trainingMethod": "adadelta",
        "inputSize": 28,
        "trainingSize": 1000,
        "testSize": 10,
        "batchSize": 10,
        "l2Decay": 0.001,
        "l1Decay": 0.001,
        "learningRate": 0.01,
        "momentum": 0.9,
        "epochs": 3,
        "augment": false,
        "logInterval": 50,
        "hiddenLayers": []
    },
    "other": {
        "formattedOutput": true
    }
}